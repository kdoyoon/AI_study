# 2-Stage Detectors

* * * 

## R-CNN

<img width="761" alt="image" src="https://user-images.githubusercontent.com/93971443/201673413-524c22eb-38ae-4f90-be42-eb2cf650cc55.png">

    - ※ sliding window :  다양한 스케일의 박스를 이미지 전체에 적용 -> 비효율적 잘 사용X
    - ※ selective search : 영역을 잘게 나눈 후 순차적으로 통합

#### Pipe line
1) 이미지를 입력 받음
2) selective search를 통해 약 2000개의 RoI 추출
    - RoI : Region of Interest
3) RoI의 크기를 CNN fc layer에 넣어야 하므로 모두 동일한 사이즈로 변경(-> warping)
    - CNN fc layer : 입력 사이즈가 고정되어 있음
4) sementic feature vector 추출
    - 각 region마다 4096-dim feature vector 추출
    - pretrained Alexnet 사용
5) (4)에서 나온 feature를 SVM을 이용하여 classify 진행
    - Input : 2000 * 4096 features
    - Output : Class(# of labels + 1(배경)) + confidence score   
      ※ confidence score : class일 확률 * IoU // bounding box 내에 해당 class가 존재할 확률
6) selective search로 부터 나온 bbox : 굉장히 rough함
7) GT에 맞도록 bbox의 중심좌표(x, y), W, H Linear regression 진행

##### <전체 process>
<img width="552" alt="image" src="https://user-images.githubusercontent.com/93971443/201682412-0da50653-6ccd-4b81-a7c8-bc4cf264b92d.png">


#### Training
- Alexnet 
  - Domain specific fine-tuning 진행
  - Dataset 구성
    - IoU > 0.5 : positive samples
    - IoU < 0.5 : negative samples
    - Positive samples - 32개 / Negative samples - 96개 
    - 총 128개의 batch 구성

- Linear SVM 
  - Dataset 구성
    - GT : positive samples
    - IoU < 0.3 : negative samples
    - Positive samples 32, negative samples 96
  - Hard negative mining
    - Hard negative : False Positive
    - 배경으로 식별하기 어려운 샘플들을 강제로 다음 배치의 negative sample로 mining 
- Bbox regressor
  - Dataset 구성
    - IoU > 0.6 : positive samples
  - Loss function
    - MSE loss

- 여기서 알 수 있는 것 : 각각의 과정마다 dataset을 다르게 구성한다.

* * *

## SPPNet

* R-CNN의 한계점을 극복하기 위해 만들어짐
  * CNN fc layer의 입력 이미지가 고정되어 있기 때문에 추가적인 warping이 필요
  * 약 2000개의 RoI가 각각 CNN을 통과해야함 -> 시간 소요 up

<img width="748" alt="image" src="https://user-images.githubusercontent.com/93971443/201682198-b17ff94c-aa9e-4734-9d5d-7cb587af2a37.png">

- R-CNN과의 차이점 : image input을 바로 CNN layer에 넣어 고정된 feature map을 얻은 후 SPP(spatial pyramid pooling)을 이용함

<img width="537" alt="image" src="https://user-images.githubusercontent.com/93971443/201683069-9f2d4fa2-65dc-4b39-9f36-f43535b9e486.png">


### SPP(spatial pyramid pooling)
<img width="581" alt="image" src="https://user-images.githubusercontent.com/93971443/201683691-832c618b-5ed0-4611-8ab2-4c045dec7c72.png">

- 다양한 RoI를 고정된 feature vector로 만들기 위해 사용
1) target bin size를 정함
2) 다음과 같이 target bin size에 맞게 pooling을 진행함 -> 각 셀마다 binning을 진행(input size에 따라 다르게 진행)

<img width="694" alt="image" src="https://user-images.githubusercontent.com/93971443/201684410-3aa83b99-5b71-4ce9-81bd-514f18b48756.png">

3) 고정된 size feature vector을 얻을 수 있음

* * * 

## Fast R-CNN

<img width="654" alt="image" src="https://user-images.githubusercontent.com/93971443/201813287-34f356a9-4e61-4396-864b-6a79838faf11.png">

#### Pipeline
1) CNN에 이미지를 넣어 feature map 추출(VGG16 사용)
2) RoI projection을 통해 feature map상에서 RoI를 계산
    - 원본이미지에서 selective search하는 것은 동일 -> 약 2000개의 region 추출
    - 원본이미지 CNN 통과 -> feature map 추출
    - 앞서 구한 region을 그대로 feature map에 적용
    - region의 사이즈 feature amp에 맞게 확대/축소 

    <img width="604" alt="image" src="https://user-images.githubusercontent.com/93971443/201813896-23fbd5d2-ed21-4ac0-b4a9-4e1c2b3481e0.png">

3) RoI pooling을 통해 일정한 크기의 feature 추출
    - 고정된 vector 얻기 위한 과정
    - SPP 사용(pyramid level : 1 / Target grid size : 7X7

4) FC layer 이후, softmax classifier와 bounding box regressor
    - class 개수 : C + 1(배경)

#### Training
- Multi task loss
    - classification loss + bounding box regressor    
   
- Loss function
    - classification : Cross Entrophy
    - bounding box regression : Smooth L1   


- Dataset
    - IoU > 0.5 : positive samples
    - 0.1 < IoU < 0.5 : negative samples
    - positive samples 25%, negative samples : 75%   

- Hierarchical sampling
    - R-CNN의 경우 이미지에 존재하는 RoI를 전부 저장해 사용
    - 한 배치에 서로 다른 이미지의 RoI가 포함됨
    - Fast R-CNN의 경우 한 배치에 한 미이지의 RoI만을 포함
    - 한 배치 안에서 연산과 메모리를 공유할 수 있음
   
--> end-to-end X : selective search를 통해 region을 추출-> CPU 상에서 돌아감-> 학습가능 알고리즘 X   

* * *

## Faster R-CNN

- R-CNN + RPN(-> Fast R-CNN의 selective search 대체)
<img width="559" alt="image" src="https://user-images.githubusercontent.com/93971443/201826038-25ccb6bd-3192-4a45-b2e2-c63b050f569c.png">

#### Pipeline
1) 이미지를 CNN에 넣어 feature map 도출
2) RPN을 통해 RoI 계산
    - 기존의 selective search 대체
    - anchor box(-> 다양한 scale & 비율의 박스들)
    - anchor box에 객체가 들어있는지, anchor box 위치 미세조정 진행

<img width="677" alt="image" src="https://user-images.githubusercontent.com/93971443/201826552-1c65da48-2355-4857-b63b-9a39783c1f60.png">

- cls layer : 객체 포함여부 알려줌
- reg layer : anchor box좌표 미세조정

<img width="715" alt="image" src="https://user-images.githubusercontent.com/93971443/201827981-4a67fab6-b995-410f-8c4c-b41976ccc2b8.png">


- ※NMS : 유사한 박스 제거하는 알고리즘
    - class score 기준으로 proposals 분류
    - IoU가 0.7 이상인 proposals 영역들은 중복된 영역으로 판단한 뒤 제거
    1) box에 대한 score 계산 후 내림차순으로 정렬
    2) 스코어가 가장 큰 box 기준으로 IoU score 계산
    3) IoU 0.7 이상인 box는 동일한 box로 취급 후 삭제   
    -> 약 1000-2000개의 RoI가 남도록 진행
    
#### Training
- RPN / Fast R-CNN 나눠 학습 진행

##### RPN(Region Proposal Network)
- classification과  regressor 학습을 위해 anchor box를 positive/negative samples로 구분
- dataset 구성
    - IoU > 0.7 or highest IoU with GT : positive samples
    - IoU < 0.3 : negative samples
    - 나머지 : 학습데이터로 사용X

- Loss 함수
<img width="348" alt="image" src="https://user-images.githubusercontent.com/93971443/201830155-781dc98e-2b34-4065-81c6-3ae01fef0561.png">   

    - 객체가 포함되는 anchor box에 대해서만 계산 진행
 ##### Fast R-CNN
 - dataset 구성
    - IoU > 0.5 : positive samples -> 32개
    - IoU < 0.5 : negative samples -> 96개
 - loss 함수
    - Fast R-CNN과 동일



### ※ 위 내용 및 이미지는 네이버 부스트캠프 교육 자료를 참고하였습니다.
