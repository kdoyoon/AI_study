# CNN Visualization

* * * 

- CNN 내부는 학습된 weighted들의 조합으로 이루어져 있어 파악하기 힘듦(black box)
- 따라서 visualization이 중요

* * *

### Visualization의 종류
- Analysis of model behaviors(모델의 특성 분석)
  - Parameter examination(filter visualization, factorization lens)
  - Feature analysis(t-SNE, Gradient ascent)
- Model decision explanation(결론 출력 분석)
  - Sensitivity analysis(Saliency map, GradCAM)
  - Decomposition(DeepLIFT, LPR)
<img width="750" alt="image" src="https://user-images.githubusercontent.com/93971443/196133418-b1a20c77-6e7a-446a-b364-1904f7bb4b24.png">

* * *

### Analysis of model behaviors
<img width="768" alt="image" src="https://user-images.githubusercontent.com/93971443/196127638-bbf3f9b4-36a4-4871-ba12-9171e13a3278.png">

- Embedding feature analysis
  - Nearest Neighbors in feature space
    - HIGH 부분의 과정
    - search the nearest neighbors of features from DB
    - DB에 미리 준비되어있는 train 데이터의 feature를 추출하여 저장함
    - 새롭게 들어오는 Query 이미지에 대해 검색된 주변 이미지들로 분석함
    - 즉, query image와 모델이 찾아낸 neighbor image간 픽셀별로 distance를 계산하여 비슷한 이미지인지 판별
      - 이미지의 위치가 다르거나 포즈가 다른 이미지 들은 올바르게 판단할 수 없는 경우가 많음(픽셀별 비교)
      - 만약 포즈가 달라도 명확하게 neighbor로 구분시엔 위치변화에 강인하게 컨셉을 제대로 학습했다는 의미
<img width="704" alt="image" src="https://user-images.githubusercontent.com/93971443/196130595-6b1b4d67-74de-42e1-92da-af12ef2485b0.png">

※ 빨간 부분: query image 미리 표현   

  - Dimentionality Reduction
    - NN in feature space -> 차원이 너무 높아 인간이 이해하기 어렵다는 단점이 있음
    - 차원을 줄여 인간이 이해할 수 있도록 함
    - t-SNE : 2차원 공간상으로 나타냄
 
<img width="517" alt="image" src="https://user-images.githubusercontent.com/93971443/196129755-03de2adb-0c2c-43a3-975e-129c4d5df675.png">

- Activation investigation
  - Layer activation
    - Behaviors of mid to high-level hidden units
    - 특정 hidden node를 선택하여 출력함
    - 선택한 hidden node의 역할을 파악할 수 있음
    - hidden node가 찾은 특징을 파악(ex. 얼굴, 난간)

<img width="558" alt="image" src="https://user-images.githubusercontent.com/93971443/196130997-3f91179b-6b0a-4c28-889d-cfe26737957e.png">

  - Maximally activation patches
    - mid-level 분석에 용이
    - Sequenece
      1. Pick a channel in a certain layer
      2. Feed a chunk of images and record each activation value(of the chosen channel)
      3. Crop image patches around maximum activation values
    - score가 가장 높은 곳의 위치를 파악하고 receptive field에서 해당 부분을 뜯어옴
   
- Class Visualization
  - 예제 데이터를 사용하지 않고 네트워크가 기억하고 있는 이미지를 시각화하여 판단
  <img width="297" alt="image" src="https://user-images.githubusercontent.com/93971443/196132214-17df587b-c9f5-4d1b-a953-553db924ff05.png">
  
  - 위 사진은 bird, dog 클래스에 대한 네트워크 예상치 확인한 결과
  - target class외에도 주변 부분(배경, 사람)도 나온 것을 볼 수 있음(->bias됨을 의심할 필요있음)
  - 이 방법은 최적화를 통해 진행
  
  <img width="456" alt="image" src="https://user-images.githubusercontent.com/93971443/196136336-f4a503bf-a256-40ac-a178-f8f06d59c516.png">
  
  - 위와 같이 2개의 loss function을 합쳐서 씀
  - 추상적인 값이 매우 클 경우 우리가 알고 있는 또는 이해할 수 있는 영상으로 유도하기 위해 사용
   
  - Gradient ascent
    - Sequenece
     1. Get a prediction score(of the target class) of a dummy image(blank or random initial)
     2. Backpropagate the gradient maximizing the target class score w.r.t the input image
     3. Update the current image

* * *

### Model decision explanation

- Saliency test
  * Occlusion map
    - 일정 부분을 가리고 예측을 진행
    <img width="780" alt="image" src="https://user-images.githubusercontent.com/93971443/196138223-17baedfa-98ed-4297-9b59-9330df5e51d2.png">
    - prediction score가 급격히 떨어진 부분은 중요한 부분임을 고려하여 heatmap으로 나타냄

  * via Backpropagation
    - Analysis of model behaviors의 gradient ascent와 유사
    - 그러나 특정 이미지를 넣어 classification에 큰 영향을 끼친 부분을 heatmap으로 표시
    - Sequence
      1. Get a class score of the target source image
      2. Backpropagate the gradient of the class score w.r.t input domain
      3. Visualize the obtained gradient magnitude map(optionally, can be accumulated)
  
   <img width="703" alt="image" src="https://user-images.githubusercontent.com/93971443/196139393-35d6d58e-50f1-467b-9880-8bfb410c7a40.png">
   
  * Rectified unit(backward pass)
    - forward 연산 시 0이하였던 unit들을 backpropagation시에도 마스킹 처리
   <img width="756" alt="image" src="https://user-images.githubusercontent.com/93971443/196141435-e2e1ee7a-490a-4dff-8758-77d231b64466.png">




