# Instance Panoptic Segmentation

* * * 

### Instance Segmetation

* Semantic segmentation + ditinguishing instances
* Mask R-CNN
  - 정수 좌표로 부터만 feature을 추출하는 ROI pooling 대신 interpolation을 사용하여 소수점까지 정교한 연산이 가능한 ROI align 사용
  -  Faster R-CNN + Mask branch
<img width="819" alt="image" src="https://user-images.githubusercontent.com/93971443/196388532-5c7145db-b9a0-4a2f-925b-19a9cefde911.png">

    - Mask branch : upsampling을 통해 채널수를 줄임, class 별로 mask 생성 후 binary prediction 진행

* YOLACT(You Only Look At CoefficienTs)
  - real time semantic segmentation
  <img width="748" alt="image" src="https://user-images.githubusercontent.com/93971443/196390213-66091224-c814-4634-88ec-f1d8ecc20820.png">
  
  - FPN을 이용하여 고해상도의 이미지를 뽑아냄
  - Mask R-CNN에서 class마다 mask를 생성한 것과 달리 추후에 mask로 합성될 수 있는 재료(soft segmentation component) prototypes 생성
  - 생성된 prototypes들과 prediction head에서 뽑아낸 mask coef와 선형 결합을 통해 mask response map을 생성

* YolactEdge
  - Yolact를 비디오에 적용한 모델
<img width="784" alt="image" src="https://user-images.githubusercontent.com/93971443/196391640-2ee94e8e-4343-4581-b992-65b504631215.png">
  
    - previous keyframe에서 key frame feature 전달
    - 소형화된 edge device에서도 빠르게 동작할 수 있도록 성능은 유지한채로 간소화

* * *

### Panoptic segmentation
* Stuff + Instances of Things
* 배경까지 고려
* UPSNet
  - FPS로 feature extraction
  - Semantic & Instance Head에서 나온 결과를 Panoptic Head에서 융합
    - Semantic : fully conv layer, Semantic prediction 결과 
    - Instance : 물체 detection, box regression, mask 추출
  <img width="751" alt="image" src="https://user-images.githubusercontent.com/93971443/196394219-5cc0fe2e-a684-427b-abda-b82a5e03c39f.png">
  
    - instance head에서 나온 결과를 semantic thing 부분과 합쳐 기존 이미지 사이즈와 맞춰줌
    - 배경에 해당하는 stuff 부분은 바로 panoptic layer로 감
    - thing 부분에다 instance 부분을 제거하고 배경에 대한 정보만 넘김
