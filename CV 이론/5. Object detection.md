# Object detection

* * *
- classification + box localization
- application
  - Autonomous driving
  - Optical Character Recognition(OCR)

* * *
## Two-stage detector

#### R-CNN
- Regions with CNN features
- Directly leverage imgae classification networks for object detection
- Sequence
  1. input image
  2. Extract region proposals
  3. Compute CNN features
  4. Classify regions
- hand design 알고리즘 사용으로 학습을 통한 성능향상 할 수 없음

#### Fast R-CNN
- Recycle a pre-computed feature for multiple object detection
- Sequence
  1. conv. feature map from the original image
  2. ROI(reason of interest) feature extraction from the feature map through ROI pooling   
    ※ 뽑아 놓은 feature를 여러 번 재활용하기 위한 layer
  3. class and box prediction for each ROI
- region Proposal에서 여전히 hand design 알고리즘 사용
<img width="612" alt="image" src="https://user-images.githubusercontent.com/93971443/195976003-916dc2d0-100d-4e4f-97be-fcf857a42bd3.png">


#### Faster R-CNN
- End-to-end object detection by neural region proposal
- Fast R-CNN보단 개선된 부분 : region Proposal(hand model -> NN)
- Time consuming selective search -> Region Proposal Network(RPN)
<img width="495" alt="image" src="https://user-images.githubusercontent.com/93971443/195975862-7b8627e9-0e4c-481a-a153-05a8c1002d94.png">

- 각 위치에서 발생할 것 같은 box 후보군을 미리 정함(anchor box)
- overlap 정도를 측정하는 IOU를 사용하여 positive/negative sample 나눔
  - IOU : $(Area of Overlap)/(Area of Union)$ 
<img width="523" alt="image" src="https://user-images.githubusercontent.com/93971443/195975970-13a682ee-c2ce-40fa-a09e-13911721221b.png">

- cls layer : object / non-object class 구별
- reg layer : (x 좌표 ,y 자표, 너비, 높이), 박스의 정교한 위치 조정

- Non-Maximum Suppression(NMS)
1. Select the box with the highest objectiveness score
2. Compare IoU of this box with other boxes
3. Remove the bounding boxes with IoU $≥$ 50%
4. Move to the next highest objectiveness score
5. Repeat steps 2-4

### R-CNN Family
<img width="687" alt="image" src="https://user-images.githubusercontent.com/93971443/195976249-217e08e1-9a05-4c93-a2c1-734f553a3230.png">

* * *

## Single-stage detector
- No explicit ROI pooling
- 정확도 포기하고 빠른 처리 가능하게 함(real time detector)
 
<img width="662" alt="image" src="https://user-images.githubusercontent.com/93971443/195976314-11613cfc-86ee-44ff-9659-31730321b318.png">

- YOLO
- SSD(Single Shot Multibox Detector)

* * *
## Focal loss
- 보통 이미지에 object보단 배경이 많기 때문에 class imbalance 문제 생김(one-stage detector)
- Cross Entrophy의 확장인 Focal loss 사용

<img width="398" alt="image" src="https://user-images.githubusercontent.com/93971443/195976446-54e8f62c-8db3-4edb-980c-9eee2048abbb.png">

- 잘 맞힌 대상엔 작은 weight 부여, 맞추지 못한 대상엔 큰 weight 부여
- gamma가 클수록 gradient sharp

## Retina Net
<img width="655" alt="image" src="https://user-images.githubusercontent.com/93971443/195976527-6fd42662-554f-4ccb-b5a0-e3941502f1ec.png">

- U-net과 유사한 구조
- concat하는 U-net과는 달리 + 연산을 통해 fusion

  ### ※ 위 내용 및 이미지는 네이버 부스트캠프 교육 자료를 참고하였습니다.
