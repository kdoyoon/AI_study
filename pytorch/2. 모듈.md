# 모듈

* * *

### nn.module
- 여러 기능을 한 곳에 모아두는 상자 역할
- 안에서 여러 함수를 정의하기도 하고 다른 모듈을 넣을 수도 있음
<pre>
<code>
import torch.nn as nn
import torch.nn.functional as F

class Mode(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(1, 20, 5)
    self.conv2 = nn.Conv2d(20, 20, 5)
  
  def forward(self, x):
    x = F.relu(self.conv1(x))
    return F.relu(self.conv2(x))
</code>
</pre>

※ super().__init__()의 역할
-부모 클래스를 초기화, 속성을 받옴(초기화 안할 속성 사용 불가)

#### 종류
- Sequential
  - 모듈을 하나로 묶어 순차적으로 실행시키고 싶을 때 사용
- ModuleList
  - list처럼 모아둔 후 원하는 것을 인덱싱을 이용하여 사용
- ModuleDict
  - dict처럼 key 값을 이용하여 호출

* List VS. ModuleList
  * 일반 list는 모듈 내에서 파라미터로 작동하지 않기 때문에 저장되지 않는다.
  * Modulelist는 파라미터로 사용이 되기 때문에 모듈에 저장이 된다.

* * *

### Parameter

모듈에서 사용되는 weight와 bias와 같은 정보를 갖는 텐서

* 왜 일반 tensor를 안쓰고 parameter를 쓸까?
  * 모듈 내에서 파라미터로 사용되어야 저장이 가능하고 이를 backward 연산시 활용할 수 있다.

#### Buffer
* 파라미터가 아닌 텐서를 저장하고 싶을 때 사용
* register_buffer를 통해 저장

#### tensor / parameter / buffer
* tensor
  * gradient 계산 X
  * 값 업데이터 X
  * 모델 저장시 값 저장 X
* parameter
  * gradient 계산 O
  * 값 업데이터 O
  * 모델 저장시 값 저장 O
* buffer
  * gradient 계산 X
  * 값 업데이터 X
  * 모델 저장시 값 저장 O
 
 ### named_children, named_modules, named_parameters
 * children : 한 단계 아래의 sub module까지만 표시
 * modules : 자신에게 속하는 모든 submodule 표시
 * parameters : 모듈의 파라미터 표시
 
 * * *
 
 ### hook, apply
 
 #### hook
 - 프로그램의 실행 로직을 분석
 - 프로그램에 추가적인 기능을 제공하고 싶을 때 사용
 - tensor hook
  - backward hook
 - module hook
  - forward
  - backward
 - <pre><code>__dict__</code></pre> 를 이용하여 생성된 hook 확인 가능
 
 
#### apply
- pre-trained 된 모듈에 내가 만든 custom 함수를 적용하고 싶을 때 사용
- 모듈을 입력으로 받음
- 가중치 초기화에 자주 사용
- postorder 방식으로 적용



### ※ 위 내용 및 이미지는 네이버 부스트캠프 교육 자료를 참고하였습니다.
