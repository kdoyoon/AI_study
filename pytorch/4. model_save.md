# Model Save

* * *

### 모델 저장
* model.save()
* 결과 공유 및 효율적 학습을 위해 모델 저장 필요
* 모델의 형태와 파라미터 저장
* 외부 연구자와 공유하여 학습 재연성 향상

<pre>
<code>
torch.save(model_name, os.path.join(MODEL_PATH, "파일명.pt"))
# state_dict() : 모델의 파라미터를 표시
# OrderedDict 형식으로 파라미터를 저장
</code>
</pre>

### 모델 LOAD

<pre>
<code>
# 파라미터만 load
new_model = TheModelClass() # 위에서 저장된 모델과 같은 형태여야함
new_model.load_state_dict(torch.load(os.path.join(MODEL_PATH, "파일명.pt")))

</code>
</pre>


* * *

#### (추가)
- 만약 모델의 architecture와 함께 저장하고 싶을시 

<pre>
<code>
torch.save(model_name, os.path.join(MODEL_PATH,"파일명.pt"))
model = torch.load(od.path.join(MODEL_PATH, "파일명.pt"))
</code>
</pre>

#### torchsummary
* layer 시각화에 사용
<pre>
<code>
$ pip install torchsummary

from torchsummary import summary

summary(model, (model_input : tuple))
</code>
</pre>


* * *

### Check Points
* 학습의 중간 결과를 저장 최선의 결과 선택을 위함
* early stopping 기법 사용 시 이전 학습 결과 저장
* loss와 metric 값을 지속적으로 확인 및 저장
* 일반적으로 epoch, loss, metric 함께 저장하여 확인
  

### ※ 위 내용 및 이미지는 네이버 부스트캠프 교육 자료를 참고하였습니다.
