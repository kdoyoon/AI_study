# 모델 결과 향상을 위한 방법
- 모델 변경
- 데이터 변경_새로운 데이터를 추가하거나 기존 데이터 내의 오류 찾기
- hyperparameter tuning

※ 모델 변경과 데이터 변경이 성능을 바꾸기 위한 가장 좋은 방법이지만, 약간의 향상을 위해서 hyperparameter tuning 사용   
※ 데이터가 많아지면서 중요도가 많이 떨어짐

### HyperParameter Tuning
- learning rate, 모델의 크기 등 모델 스스로 학습하지 않은 값을 HyperParameter라 함
- 기본적인 방법
  - gird : 일정 범위를 정해 조정
  - random : random search하다가 잘 나오는 구간에서 grid search 진행
- 최근에는 베이지안 기반 기법들이 주도

#### RAY
- Multi-node, Multi-Processing 지원 모듈
- ML/DL 병렬 처리를 위해 개발된 모듈
- 분산병렬 ML/DL 모듈의 표준
- HyperParameter search를 위한 다양한 모듈 제공   
※ ray를 사용할 때 모델의 전과정이 하나의 함수에 다 들어있어야한다.


```python
!pip install ray
!pip install tensorboardX #레이자체 tensorboardX를 사용

# 1) 학습공간 지정
config = {'l1' : tune.sample_from(lambda _ : 2**np.random.randint(2,9)),
          'l2' : tune.sample_from(lambda _ : 2**np.random.randint(2,9)),
          'lr' : tune.loguniform(1e-4, 1e-1), 'batch_size' = tune.choice([2,4,8,16])}

# 2) 스케쥴러 지정을 통해 의미 없는 알고리즘 
scheduler = ASHAScheduler(
  metric = "loss", mode = "min", max_t = max_num_epochs, grace_period = 1, reduction_factor = 2)

# 3) 결과 출력 양식 지정
reporter = CLIReporter(
          metric_columns = ['loss', 'accuracy', 'training_iteration'])
          
# 4) 병렬 처리 양식으로 학습 시행
result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter)
```




### ※ 위 내용 및 이미지는 네이버 부스트캠프 교육 자료를 참고하였습니다.
